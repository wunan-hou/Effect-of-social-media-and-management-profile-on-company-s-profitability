{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google_auth_oauthlib.flow\n",
    "import googleapiclient.discovery\n",
    "import googleapiclient.errors\n",
    "\n",
    "scopes = [\"https://www.googleapis.com/auth/youtube.readonly\"]\n",
    "\n",
    "def main():\n",
    "    os.environ[\"OAUTHLIB_INSECURE_TRANSPORT\"] = \"1\"\n",
    "\n",
    "    api_service_name = \"youtube\"\n",
    "    api_version = \"v3\"\n",
    "    client_secrets_file = \"client_secret_160082816643-fg0vg2jbqsissg5ee5br8isedbdvmlvu.apps.googleusercontent.com.json\"\n",
    "\n",
    "    # Get credentials and create an API client\n",
    "    flow = google_auth_oauthlib.flow.InstalledAppFlow.from_client_secrets_file(\n",
    "        client_secrets_file, scopes)\n",
    "    credentials = flow.run_console()\n",
    "    youtube = googleapiclient.discovery.build(\n",
    "        api_service_name, api_version, credentials=credentials)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get YouTube channel ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from pandas import read_excel\n",
    "df = pd.read_excel('D&B dataset.xlsx')[['name','youtube']]\n",
    "df = df[df['youtube'].notnull()]\n",
    "df = df.set_index('name')\n",
    "df['viewCount'] = np.nan\n",
    "df['commentCount'] = np.nan\n",
    "df['subscriberCount'] = np.nan\n",
    "df['videoCount'] = np.nan\n",
    "df['liked'] = np.nan\n",
    "df['disliked'] = np.nan\n",
    "df['views'] = np.nan\n",
    "df['comment'] = np.nan\n",
    "df['category'] = np.nan\n",
    "df['video_2017'] = np.nan\n",
    "df['video_2018'] = np.nan\n",
    "df['first'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "youTubeApiKey='AIzaSyBLKmZxYRmgfjskAZuxMVQgVWTu4LAQMqs'\n",
    "list_3 = list()\n",
    "bad_link3 = list()\n",
    "for i in list_2:\n",
    "    if i[1].strip('/').split(\"/\")[-1].startswith('UC'):\n",
    "        list_3.append((i[0],i[1].strip('/').split(\"/\")[-1][0:24]))\n",
    "    elif i[1].strip('/').split(\"/\")[-1].startswith('watch?'):\n",
    "        video_id = i[1].strip('/').split(\"/\")[-1][8:19]\n",
    "        url = f'https://www.googleapis.com/youtube/v3/videos?id={video_id}&key={youTubeApiKey}&part=snippet'\n",
    "        try:\n",
    "            channnel_id = requests.get(url).json()['items'][0]['snippet']['channelId']\n",
    "            list_3.append((i[0],channel_id))\n",
    "        except:\n",
    "            bad_link3.append(i)  \n",
    "    else:\n",
    "        user_name = i[1].strip('/').split(\"/\")[-1]\n",
    "        url = f'https://www.googleapis.com/youtube/v3/channels?key={youTubeApiKey}&forUsername={user_name}&part=id'\n",
    "        try:\n",
    "            response = requests.get(url).json()\n",
    "            channel_id =response['items'][0]['id']\n",
    "            list_3.append((i[0],channel_id))\n",
    "        except:\n",
    "            bad_link3.append(i) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### search unformated youtube websites and get their channel ID "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_list = [i[0] for i in bad_link3]\n",
    "channel_id = list()\n",
    "no_result = list()\n",
    "for name in bad_list:\n",
    "    try:\n",
    "        request = youtube.search().list(\n",
    "            part=\"snippet\",\n",
    "            maxResults=1,\n",
    "            q=name).execute()\n",
    "        channel_id.append((name,request['items'][0]['snippet']['channelTitle'],request['items'][0]['snippet']['channelId']))\n",
    "    except:\n",
    "        no_result.append(name)\n",
    "\n",
    "good_link3 = list()\n",
    "for i in channel_id:\n",
    "    if [i.lower() for i in i[0].split()][0] == [i.lower() for i in i[1].split()][0]:\n",
    "        good_link3.append((i[0],i[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### collect viewCount, subscriberCount, and videoCount "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_videos = dict()\n",
    "for i in list_3:\n",
    "    videos = list()\n",
    "    id_ = i[1]\n",
    "    url = f'https://www.googleapis.com/youtube/v3/channels?id={id_}&key={youTubeApiKey}&part=contentDetails,statistics'\n",
    "    try:\n",
    "        response = requests.get(url).json()\n",
    "        data['viewCount'][i[0]] = response['items'][0]['statistics']['viewCount']\n",
    "        data['subscriberCount'][i[0]] = response['items'][0]['statistics']['subscriberCount']\n",
    "        data['videoCount'][i[0]] = response['items'][0]['statistics']['videoCount']\n",
    "        playlist_id = response['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
    "        next_page_token = None\n",
    "        while True:\n",
    "            try:\n",
    "                res = youtube.playlistItems().list(playlistId=playlist_id,\n",
    "                                                       part='snippet',\n",
    "                                                       maxResults=50,\n",
    "                                                       pageToken=next_page_token).execute()\n",
    "                videos += res['items']\n",
    "                next_page_token = res.get('nextPageToken')\n",
    "                if next_page_token is None:\n",
    "                    break\n",
    "            except:\n",
    "                print((i[0],playlist_id))\n",
    "                break\n",
    "    except:\n",
    "        print('bad channel id',i)\n",
    "    company_videos[i[0]] = list(map(lambda x:x['snippet']['resourceId']['videoId'], videos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gather video ID "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_video = list()\n",
    "error_video = list()\n",
    "dict_stat3 = dict()\n",
    "for name, n in company_videos.items():\n",
    "    stats = []\n",
    "    if len(n) > 0:\n",
    "        for i in range(0, len(n),40):\n",
    "            try:\n",
    "                res = (youtube).videos().list(id=','.join(n[i:i+40]),part='statistics,snippet').execute()\n",
    "                stats += res['items']\n",
    "            except:\n",
    "                error_video.append((name,n[i]))\n",
    "                print('error')\n",
    "        dict_stat3[name] = stats\n",
    "    else:\n",
    "        no_video.append(name)\n",
    "        print('empty',name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### collect other statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = list()\n",
    "category = list()\n",
    "time2 = list()\n",
    "category2 = list()\n",
    "liked=[]\n",
    "disliked=[]\n",
    "views=[]\n",
    "comment=[]\n",
    "for key, value in dict_stat3.items():\n",
    "    like_ = 0\n",
    "    dislike_ = 0\n",
    "    views_ = 0\n",
    "    comment_ = 0\n",
    "    time = list()\n",
    "    category = list()\n",
    "    for i in value:\n",
    "        if i['statistics'].get('likeCount'):\n",
    "            like_ += int(i['statistics']['likeCount'])\n",
    "        if i['statistics'].get('dislikeCount'):   \n",
    "            dislike_ += int(i['statistics']['dislikeCount'])\n",
    "        if i['statistics'].get('viewCount'):\n",
    "            views_ += int(i['statistics']['viewCount'])\n",
    "        if i['statistics'].get('commentCount'):\n",
    "            comment_ += int(i['statistics']['commentCount'])\n",
    "        time.append(i['snippet']['publishedAt'])\n",
    "        category.append(i['snippet']['categoryId'])\n",
    "    \n",
    "    # video category\n",
    "    from itertools import groupby\n",
    "    from functools import reduce\n",
    "    cate_pairs = map(lambda x:(x,1),category)\n",
    "    sorted_= sorted(cate_pairs)\n",
    "    groups = groupby(sorted_,lambda x:x[0])\n",
    "    unpacked = map(lambda x: [x[0]]+list(map(lambda y:y[1],x[1])),groups)\n",
    "    cate_count = map(lambda x: [x[0]] + [reduce(lambda a,b: a + b, x[1:])], unpacked)\n",
    "    \n",
    "    # time of the first video posted, # of videos in 2017 and 2018\n",
    "    c2017 = 0\n",
    "    c2018 = 0\n",
    "    first_ = sorted(time)[0]\n",
    "    for i in time:\n",
    "        if i[0:4] == '2017':\n",
    "            c2017 +=1\n",
    "        elif i[0:4] == '2018':\n",
    "            c2018 +=1\n",
    "    \n",
    "    df['liked'][key] = like_\n",
    "    df['disliked'][key] = dislike_\n",
    "    df['views'][key] = views_\n",
    "    df['comment'][key] = comment_\n",
    "    df['category'][key] = list(cate_count)\n",
    "    df['video_2017'][key] = c2017\n",
    "    df['video_2018'][key] = c2018\n",
    "    df['first'][key] = 2017-int(first_[0:4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
